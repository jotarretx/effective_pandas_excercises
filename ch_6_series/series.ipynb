{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "A panda Series is one of two core pandas objects (the other being a DataFrame). It is a one dimensional array-like object used to model one column or row of data. It is the building block of a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Object\n",
    "Showing what really is a pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Python\n",
    "series = {\n",
    "    \"index\": [0, 1, 2, 3],\n",
    "    \"data\": [145, 142, 38, 13],\n",
    "    \"name\": \"songs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short function to pull items from the data structure\n",
    "def get(series, idx):\n",
    "    value_idx = series[\"index\"].index(idx)\n",
    "    return series[\"data\"][value_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(series, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = {\n",
    "    \"index\":['Paul', 'John', 'George', 'Ringo'],\n",
    "    \"data\":[145, 142, 38, 13],\n",
    "    \"name\":\"counts\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get(songs, \"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example showcases what a pandas Series does, making it possible to support other index types, like strings or dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default NumPy backend\n",
    "songs2 = pd.Series([145, 142, 38, 13], name=\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    145\n",
       "1    142\n",
       "2     38\n",
       "3     13\n",
       "Name: counts, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs3 = pd.Series([145, 142, 38, 13], name=\"counts\", dtype=\"int64[pyarrow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    145\n",
       "1    142\n",
       "2     38\n",
       "3     13\n",
       "Name: counts, dtype: int64[pyarrow]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pyarrow backend is more efficient in computation and memory usage, plus it allows for\n",
    "missing values, a native string type, speed enhancements, and memory\n",
    "optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index can be string-based as well, in which case pandas indicates\n",
    "that the datatype for the index is object (not string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs4 = pd.Series(\n",
    "    [145, 142, 38, 13],\n",
    "    name=\"counts\",\n",
    "    dtype=\"int64[pyarrow]\",\n",
    "    index=['Paul', 'John', 'George', 'Ringo']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Paul', 'John', 'George', 'Ringo'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs4.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series data does not need to be numeric or homogenous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting an object\n",
    "class Foo:\n",
    "    pass\n",
    "\n",
    "ringo = pd.Series(\n",
    "    ['Richard', 'Starkey', 13, Foo()],\n",
    "    name=\"ringo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    Richard\n",
       "1                                    Starkey\n",
       "2                                         13\n",
       "3    <__main__.Foo object at 0x7f63748cc2b0>\n",
       "Name: ringo, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ringo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The NA value\n",
    "Depending on the backend, we will see NA (pyarrow) or NaN (NumPy) values. However, the NumPy only supports for missing numbers in floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ono        2.0\n",
       "Clapton    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will coerce the type to float\n",
    "nan_series = pd.Series(\n",
    "    [2, np.nan],\n",
    "    index=['Ono', 'Clapton']\n",
    ")\n",
    "nan_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ono           2\n",
       "Clapton    <NA>\n",
       "dtype: int64[pyarrow]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will still be of type int!\n",
    "nan_series2 = pd.Series(\n",
    "    [2, np.nan],\n",
    "    index=['Ono', 'Clapton'],\n",
    "    dtype='int64[pyarrow]'\n",
    ")\n",
    "nan_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas ignore NA in arithmetic operations\n",
    "nan_series2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But it includes it in the total number of entries\n",
    "nan_series2.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_ser = np.array([145, 142, 38, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series: 142\n",
      "NumPy: 142\n"
     ]
    }
   ],
   "source": [
    "# Comparing with same pyarrow Series (songs3)\n",
    "print(\"Series:\",songs4.iloc[1]) # Although the iloc can be avoided too, as we can index by name we want to be specific\n",
    "print(\"NumPy:\",numpy_ser[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series mean: 84.5\n",
      "NumPy mean: 84.5\n"
     ]
    }
   ],
   "source": [
    "# There are some similar methods, like mean\n",
    "print(\"Series mean:\", songs4.mean())\n",
    "print(\"NumPy mean:\", numpy_ser.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually check all methods that are common to both types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common methods: 111\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of common methods:\", len(set(dir(numpy_ser)) & set(dir(songs4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the full list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'clip',\n",
       " 'copy',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'flags',\n",
       " 'item',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'prod',\n",
       " 'ravel',\n",
       " 'repeat',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dir(numpy_ser)) & set(dir(songs4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use boolean arrays to work as masks for filtering items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = songs4 > songs4.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paul       True\n",
       "John       True\n",
       "George    False\n",
       "Ringo     False\n",
       "Name: counts, dtype: bool[pyarrow]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paul    145\n",
       "John    142\n",
       "Name: counts, dtype: int64[pyarrow]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the mask as a filter:\n",
    "songs4[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also supports filtering with boolean arrays, but does not have the .median method. It has nonetheless a median function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145, 142])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = numpy_ser > np.median(numpy_ser)\n",
    "numpy_ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"s\", \"m\", \"l\"], dtype= \"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    s\n",
       "1    m\n",
       "2    l\n",
       "dtype: category\n",
       "Categories (3, object): ['l', 'm', 's']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case the series represents size, so there should be a natural order, but by default it doesn't have\n",
    "s.cat.ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a type so that we order them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series([\"m\",\"l\",\"xs\",\"s\",\"xl\"], dtype=\"string[pyarrow]\")\n",
    "size_type = pd.CategoricalDtype(\n",
    "    categories=[\"s\",\"m\",\"l\"],\n",
    "    ordered= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s2.astype(size_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      m\n",
       "1      l\n",
       "2    NaN\n",
       "3      s\n",
       "4    NaN\n",
       "dtype: category\n",
       "Categories (3, object): ['s' < 'm' < 'l']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, as there were some categories not covered by the size_type, they are transformed to NaN when casting with .astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given the ordering, only M and L should be True\n",
    "s3>\"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add ordering information to existing categorical data (instead of creating from scratch). However, we need to make sure to cover all categories or we would get a ValueError as per below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "items in new_categories are not the same as in old categories",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/effective_pandas_excercises/venv/lib/python3.10/site-packages/pandas/core/accessor.py:112\u001b[0m, in \u001b[0;36mPandasDelegate._add_delegate_accessors.<locals>._create_delegator_method.<locals>.f\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delegate_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/effective_pandas_excercises/venv/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:2941\u001b[0m, in \u001b[0;36mCategoricalAccessor._delegate_method\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2938\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[1;32m   2940\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, name)\n\u001b[0;32m-> 2941\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Series(res, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n",
      "File \u001b[0;32m~/effective_pandas_excercises/venv/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:1278\u001b[0m, in \u001b[0;36mCategorical.reorder_categories\u001b[0;34m(self, new_categories, ordered)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03mReorder categories as specified in new_categories.\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;124;03m                 ordered=True, dtype='category')\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(new_categories)\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mdifference(new_categories)\u001b[38;5;241m.\u001b[39mempty\n\u001b[1;32m   1277\u001b[0m ):\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems in new_categories are not the same as in old categories\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1280\u001b[0m     )\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_categories(new_categories, ordered\u001b[38;5;241m=\u001b[39mordered)\n",
      "\u001b[0;31mValueError\u001b[0m: items in new_categories are not the same as in old categories"
     ]
    }
   ],
   "source": [
    "s = pd.Series([\"s\",\"m\",\"l\"], dtype= \"category\")\n",
    "s.cat.reorder_categories([\"xs\",\"s\",\"m\",\"l\",\"xl\"], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this, we need to make sure that we have all categories in the initial Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    s\n",
       "1    m\n",
       "2    l\n",
       "dtype: category\n",
       "Categories (5, object): ['xs' < 's' < 'm' < 'l' < 'xl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    s\n",
    "    .cat.add_categories([\"xs\",\"xl\"])\n",
    "    .cat.reorder_categories([\"xs\",\"s\",\"m\",\"l\",\"xl\"], ordered=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      L\n",
       "2    NaN\n",
       "3      S\n",
       "4    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As a sidenote, we can take advantage off different atributes of the string and datetime series to perform common operations, even if they are categorical. \n",
    "# However, this would transform it into the object type deleting the category!:\n",
    "s3.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      L\n",
       "2    NaN\n",
       "3      S\n",
       "4    NaN\n",
       "dtype: category\n",
       "Categories (3, object): ['S' < 'M' < 'L']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hence, we would need to rearrange categories:\n",
    "(\n",
    "    s3\n",
    "    .str.upper()\n",
    "    .astype(\"category\")\n",
    "    .cat.reorder_categories([\"S\",\"M\",\"L\"], ordered=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyarrow also has a category type called dictionary, but there is no convenient way of creating one, hence it is recommended to use pandas \"category\" type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Pyarrow's dictionary type\n",
    "dict_type = pd.ArrowDtype(pa.dictionary(pa.int64(), pa.utf8()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = pd.Series([\"m\",\"l\",\"xs\",\"s\",\"xl\"], dtype=dict_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     m\n",
       "1     l\n",
       "2    xs\n",
       "3     s\n",
       "4    xl\n",
       "dtype: dictionary<values=string, indices=int64, ordered=0>[pyarrow]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If one were to save a categorical column into a feather file, once it is read back it will be of the dictionary type:\n",
    "(\n",
    "    pd.Series([\"s\",\"m\",\"l\"], dtype=\"category\")\n",
    "    .rename(\"size\")\n",
    "    .to_frame()\n",
    "    .to_feather(\"/tmp/cat.ft\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dictionary<values=string, indices=int8, ordered=0>[pyarrow]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    pd.read_feather(\"/tmp/cat.ft\", dtype_backend=\"pyarrow\")\n",
    "    .loc[:, \"size\"]\n",
    "    .dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    30\n",
      "1    34\n",
      "4    30\n",
      "5    32\n",
      "dtype: int64\n",
      "mean: 29.714285714285715\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a series with the temperature values for the last\n",
    "# seven days. Filter out the values below the mean.\n",
    "temp = pd.Series([30,34,28,25,30,32,29])\n",
    "print(temp[temp>temp.mean()])\n",
    "print(\"mean:\",temp.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a series with your favorite colors. Use a\n",
    "# categorical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Red\n",
       "1     Blue\n",
       "2    Black\n",
       "dtype: category\n",
       "Categories (3, object): ['Black', 'Blue', 'Red']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colours = pd.Series([\"Red\", \"Blue\", \"Black\"], dtype=\"category\")\n",
    "colours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "The Zen of Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
